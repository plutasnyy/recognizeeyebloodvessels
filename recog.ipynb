{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {}
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/plutasnyy/recognizeeyebloodvessels/blob/master/recog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "7O3ySi1WGGMl",
    "outputId": "022b0ec3-4359-478b-b670-4ec7d62106e1",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# You can change the directory name\n",
    "from IPython import get_ipython\n",
    "LOG_DIR = 'tb_logs'\n",
    "\n",
    "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "# !unzip ngrok-stable-linux-amd64.zip\n",
    "\n",
    "# import os\n",
    "# if not os.path.exists(LOG_DIR):\n",
    "#   os.makedirs(LOG_DIR)\n",
    "  \n",
    "# get_ipython().system_raw(\n",
    "#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "#     .format(LOG_DIR))\n",
    "\n",
    "# get_ipython().system_raw('./ngrok http 6006 &')\n",
    "\n",
    "# !curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "id": "2DhbcDQM9LLn",
    "outputId": "99013a26-eb3a-4514-995d-b01ba01fbdd0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from collections import Counter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from numpy import asarray\n",
    "from skimage import transform, exposure\n",
    "from skimage.filters import sobel\n",
    "\n",
    "import sklearn\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.basicConfig(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATCH_SIZE = 48\n",
    "HALF_OF_PATCH_SIZE = int(PATCH_SIZE / 2)\n",
    "SPLIT_PATCHES_SIZE = 500\n",
    "FILE_PATH = 'new_best2.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def correct_image(image):\n",
    "    #TODO run this function only when process tensor, not during creating an object\n",
    "    logging.info('Correct an image with shape: {}'.format(image.shape))\n",
    "    bw_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    image_adapt = exposure.equalize_adapthist(bw_image)\n",
    "    logarithmic_corrected = exposure.adjust_log(image_adapt, 1)\n",
    "    return logarithmic_corrected\n",
    "  \n",
    "def draw_images(images: list):\n",
    "    logging.info('Draw {} images'.format(len(images)))\n",
    "    size = np.ceil(np.sqrt(len(images)))\n",
    "    fig = plt.figure(figsize=(32, 32))\n",
    "    for i, img in enumerate(images):\n",
    "        fig.add_subplot(size, size, i + 1)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_grey_image(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, base_image, vessels, mask, id):\n",
    "        assert base_image.size == vessels.size, 'Images have different sizes'\n",
    "        assert mask.size == vessels.size, 'Mask has wrong size'\n",
    "\n",
    "        long_edge = max(base_image.size)\n",
    "        #scale = LONG_EDGE_SIZE / long_edge\n",
    "        scale=1\n",
    "        w, h = base_image.size\n",
    "        c = len(base_image.getbands())\n",
    "        w, h = int(w * scale), int(h * scale)\n",
    "        logging.info(\n",
    "            'Tensor resize from {} to {} with {} scale'.format((base_image.size, c), (w, h, c), round(scale, 2)))\n",
    "\n",
    "        self.base_image = asarray(base_image.resize((w, h), resample=Image.NEAREST))  # 0-255\n",
    "        self.corrected = correct_image(self.base_image)  # 0-1 TODO VERY BAD DEPENDENCY it should be moved out from this class\n",
    "        self.vessels = (asarray(vessels.resize((w, h), resample=Image.NEAREST)) / 255).astype(int)  # 0-1\n",
    "\n",
    "        if len(self.vessels.shape) == 3:\n",
    "            self.vessels = self.vessels[:, :, 1]\n",
    "\n",
    "        self.mask = (asarray(mask.resize((w, h))) / 255).astype(int)  # 0-1\n",
    "        self.id = id\n",
    "\n",
    "    def draw_tensor(self):\n",
    "        \"\"\"\n",
    "        TODO This is very bad dependency to other functionality, this class should be independent, it was created only for tests and it should be removed when will be unused\n",
    "        \"\"\"\n",
    "        from image_processor import draw_images\n",
    "        draw_images([self.base_image, self.corrected, self.vessels, self.mask])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}: base_image: {}'.format(self.id, self.base_image.shape)\n",
    "\n",
    "def create_tensor_from_file():\n",
    "    images_path = sorted(glob.glob('train/*'))\n",
    "    for i in range(0, len(images_path), 3):\n",
    "        file_name = images_path[i].replace('/', '.').split('.')[1]\n",
    "        logging.info('Process filepath: {}, fileName: {}, i: {}'.format(images_path[i], file_name, i))\n",
    "        base_image = Image.open(images_path[i])\n",
    "        mask = Image.open(images_path[i + 1])\n",
    "        vessels = Image.open(images_path[i + 2])\n",
    "        yield Tensor(base_image, vessels, mask, i)\n",
    "\n",
    "def create_samples_from_tensor(tensor: Tensor):\n",
    "    logging.info('Create samples from tensor: {}'.format(tensor))\n",
    "    X, Y = list(), list()\n",
    "    for (x, y), value in np.ndenumerate(tensor.mask):\n",
    "        if x + PATCH_SIZE <= tensor.corrected.shape[0] and y + PATCH_SIZE <= tensor.corrected.shape[1]:\n",
    "            center_x, center_y = x + HALF_OF_PATCH_SIZE, y + HALF_OF_PATCH_SIZE\n",
    "            if tensor.mask[center_x][center_y] == 1:\n",
    "                X.append(tensor.corrected[x: x + PATCH_SIZE, y: y + PATCH_SIZE])\n",
    "                Y.append(tensor.vessels[center_x][center_y])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_undersampling(X, y):\n",
    "    \"\"\"\n",
    "    In this moment we will lose order of samples\n",
    "    \"\"\"\n",
    "    minority_value, majority_value = 1, 0\n",
    "    new_X, new_y = list(), list()\n",
    "    length = len(y)\n",
    "    quantity_of_minority = sum(y)\n",
    "    quantity_of_majority = length - quantity_of_minority\n",
    "    indexes_list = list(range(length))\n",
    "    random.shuffle(indexes_list)\n",
    "    skipped, to_skip = 0, quantity_of_majority - quantity_of_minority\n",
    "    assert to_skip >= 0\n",
    "    for index in indexes_list:\n",
    "        if skipped < to_skip and y[index] == majority_value:\n",
    "            skipped += 1\n",
    "        else:\n",
    "            new_X.append(X[index])\n",
    "            new_y.append(y[index])\n",
    "\n",
    "    result_X, result_Y = sklearn.utils.shuffle(new_X, new_y, random_state=0)\n",
    "    return result_X, result_Y\n",
    "\n",
    "\n",
    "def preprocess_image(tensor: Tensor):\n",
    "    logging.info('Started preprocess a tensor: {}'.format(tensor))\n",
    "    edge_sobel = sobel(tensor.corrected)\n",
    "    normalized_image = cv2.normalize(edge_sobel, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    _, thresholded_image = cv2.threshold(normalized_image, 20, 255, cv2.THRESH_BINARY)\n",
    "    cleaned_image = (thresholded_image * tensor.mask).astype(int)\n",
    "    return np.invert(cleaned_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Process filepath: train/001.JPG, fileName: 001, i: 0\n",
      "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
      "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
      "INFO:root:Create samples from tensor: 0: base_image: (2336, 3504, 3)\n",
      "INFO:root:Patches were created\n",
      "INFO:root:Original dataset shape Counter({0: 6390520, 1: 408418})\n",
      "DEBUG:root:Resampled dataset shape Counter({1: 408418, 0: 408418})\n",
      "INFO:root:Splitting set. Range: 0:500 Progress of this tensor: 0% Time: 2019-05-06 10:32:40\n",
      "INFO:root:Cut dataset result countered shape Counter({0: 273, 1: 227})\n",
      "DEBUG:root:Shape X: (500, 48, 48, 1), y: (500, 2)\n",
      "INFO:root:Process filepath: train/003.jpg, fileName: 003, i: 3\n",
      "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
      "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
      "INFO:root:Create samples from tensor: 3: base_image: (2336, 3504, 3)\n"
     ]
    }
   ],
   "source": [
    "complete_X, complete_y = None, None\n",
    "for tensor in create_tensor_from_file():\n",
    "    X, y = create_samples_from_tensor(tensor)\n",
    "\n",
    "    logging.info('Patches were created')\n",
    "    logging.info('Original dataset shape {}'.format(Counter(y)))\n",
    "    X, y = random_undersampling(X, y)\n",
    "\n",
    "    logging.debug('Resampled dataset shape {}'.format(Counter(y)))\n",
    "\n",
    "    start_index = 0\n",
    "    end_index = min(start_index + SPLIT_PATCHES_SIZE, len(X))  # tricky way to avoid OutOfIndexError\n",
    "    logging.info('Splitting set. Range: {}:{} Progress of this tensor: {}% Time: {}'.format(\n",
    "        start_index, end_index, round(start_index / len(X) * 100), strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())))\n",
    "    X_subset, y_subset = X[start_index:end_index], y[start_index:end_index]\n",
    "    logging.info('Cut dataset result countered shape {}'.format(Counter(y_subset)))\n",
    "\n",
    "    X_subset = np.array(X_subset).reshape(len(X_subset), PATCH_SIZE, PATCH_SIZE, 1)\n",
    "    y_subset = to_categorical(y_subset)\n",
    "    logging.debug('Shape X: {}, y: {}'.format(X_subset.shape, y_subset.shape))\n",
    "    \n",
    "    \n",
    "    if complete_X is None:\n",
    "        complete_X = deepcopy(X_subset)\n",
    "        complete_y = deepcopy(y_subset)\n",
    "    else:\n",
    "        complete_X = np.vstack((complete_X, deepcopy(X_subset)))\n",
    "        complete_y = np.vstack((complete_y, deepcopy(y_subset)))\n",
    "\n",
    "\n",
    "\n",
    "print(complete_X.shape)\n",
    "print(complete_y.shape)\n",
    "logging.info('Complete dataset result countered shape {}'.format(Counter(complete_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pluto/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pluto/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pluto/anaconda3/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pluto/anaconda3/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:root:Created keras model\n"
     ]
    }
   ],
   "source": [
    "tb_call_back = keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=True,\n",
    "                                                write_images=True)\n",
    "checkpoint = ModelCheckpoint(FILE_PATH, save_weights_only=False, monitor='val_acc', verbose=0,\n",
    "                                          save_best_only=True, mode='max')\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(PATCH_SIZE, PATCH_SIZE, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "logging.info('Created keras model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    input = X\n",
    "    if len(input.shape) == 2:\n",
    "        input = input.reshape(1, PATCH_SIZE, PATCH_SIZE, 1)\n",
    "        logging.debug('Reshaped before prediction')\n",
    "    result = model.predict(input)\n",
    "    logging.debug('Predicted: {}, return {}'.format(result, np.argmax(result)))\n",
    "    logging.debug('For: {}'.format(input))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, validation_split=0.1, epochs=150, batch_size=32, callbacks=[tb_call_back, checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(FILE_PATH)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6Knq5GMTex4",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "!rm -rf tb_logs* Graph"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "recog.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
