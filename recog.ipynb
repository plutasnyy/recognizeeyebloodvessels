{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recog.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USZVSMyr0G-Y",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "### Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsqIed0l0K10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "1c652bdd-3128-4012-e2cf-919e6541f1d3",
        "pycharm": {}
      },
      "source": "from scipy import ndimage\n!git clone https://github.com/plutasnyy/recognizeeyebloodvessels.git",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into \u0027recognizeeyebloodvessels\u0027...\n",
            "remote: Enumerating objects: 1134, done.\u001b[K\n",
            "remote: Total 1134 (delta 0), reused 0 (delta 0), pack-reused 1134\u001b[K\n",
            "Receiving objects: 100% (1134/1134), 190.43 MiB | 13.26 MiB/s, done.\n",
            "Resolving deltas: 100% (780/780), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFye3vkR0b9m",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "### Importy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "PNwfNmJXz7r-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f82b513f-533f-46fb-d868-926348715588"
      },
      "source": "import logging\nimport os\nimport glob\nimport random\nfrom IPython import get_ipython\n\nimport keras\nfrom keras import backend as K\nfrom keras import Sequential\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\nfrom keras.utils import to_categorical\nfrom keras.optimizers import SGD\n\nimport tensorflow as tf\nfrom tensorflow.python.client import device_lib\n\nfrom collections import Counter\nfrom time import gmtime, strftime\n\nfrom PIL import Image\nfrom copy import deepcopy\nfrom numpy import asarray\nfrom skimage import transform, exposure\nfrom skimage.filters import sobel\n\nimport sklearn\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "NqkqIZDLz7sC",
        "colab_type": "text"
      },
      "source": [
        "### Zmiene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "fgf3O4aUz7sD",
        "colab_type": "code",
        "colab": {}
      },
      "source": "PATCH_SIZE \u003d 48\nHALF_OF_PATCH_SIZE \u003d int(PATCH_SIZE / 2)\nSPLIT_PATCHES_SIZE \u003d 2500\nBASE_PATH \u003d \u0027data\u0027\nIMAGE_PATH \u003d BASE_PATH + \u0027/image/{}.jpg\u0027\nMASK_PATH \u003d BASE_PATH + \u0027/mask/{}.tif\u0027\nMANUAL_PATH \u003d BASE_PATH + \u0027/manual/{}.tif\u0027\nFILE_PATH \u003d \u0027new_best2.hdf5\u0027\nLOG_DIR \u003d \u0027tb_logs\u0027\nLONG_EDGE_SIZE \u003d None\n\n\nos.environ[\u0027TF_CPP_MIN_LOG_LEVEL\u0027] \u003d \u00272\u0027\nlogging.basicConfig(level\u003dlogging.INFO)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "cKj0luElz7sF",
        "colab_type": "text"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7O3ySi1WGGMl",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# import os\n",
        "# if not os.path.exists(LOG_DIR):\n",
        "#   os.makedirs(LOG_DIR)\n",
        "  \n",
        "# get_ipython().system_raw(\n",
        "#     \u0027tensorboard --logdir {} --host 0.0.0.0 --port 6006 \u0026\u0027\n",
        "#     .format(LOG_DIR))\n",
        "\n",
        "# get_ipython().system_raw(\u0027./ngrok http 6006 \u0026\u0027)\n",
        "\n",
        "# !curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "#     \"import sys, json; print(json.load(sys.stdin)[\u0027tunnels\u0027][0][\u0027public_url\u0027])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        },
        "id": "Rr_kJmuxz7sH",
        "colab_type": "text"
      },
      "source": [
        "### Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "8RVoB1pnz7sI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_image(image):\n",
        "    #TODO run this function only when process tensor, not during creating an object\n",
        "    logging.info(\u0027Correct an image with shape: {}\u0027.format(image.shape))\n",
        "    bw_image \u003d cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    image_adapt \u003d exposure.equalize_adapthist(bw_image)\n",
        "    logarithmic_corrected \u003d exposure.adjust_log(image_adapt, 1)\n",
        "    return logarithmic_corrected\n",
        "  \n",
        "def draw_images(images: list):\n",
        "    logging.info(\u0027Draw {} images\u0027.format(len(images)))\n",
        "    size \u003d np.ceil(np.sqrt(len(images)))\n",
        "    fig \u003d plt.figure(figsize\u003d(32, 32))\n",
        "    for i, img in enumerate(images):\n",
        "        fig.add_subplot(size, size, i + 1)\n",
        "        plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def draw_grey_image(image):\n",
        "    plt.imshow(image, cmap\u003d\u0027gray\u0027)\n",
        "    plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        },
        "id": "qAv8KAJiz7sK",
        "colab_type": "text"
      },
      "source": [
        "### Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "ePVowPN-z7sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": "class Tensor:\n    def __init__(self, base_image, vessels\u003dNone, mask\u003dNone, id\u003dNone):\n        # long_edge \u003d max(base_image.size)\n        # scale \u003d LONG_EDGE_SIZE / long_edge\n        scale\u003d1\n        w, h \u003d base_image.size\n        c \u003d len(base_image.getbands())\n        w, h \u003d int(w * scale), int(h * scale)\n        logging.info(\n            \u0027Tensor resize from {} to {} with {} scale\u0027.format((base_image.size, c), (w, h, c), round(scale, 2)))\n\n        self.base_image \u003d asarray(base_image.resize((w, h), resample\u003dImage.NEAREST))  # 0-255\n        self.corrected \u003d correct_image(self.base_image)  # 0-1 TODO VERY BAD DEPENDENCY it should be moved out from this class\n        \n        if vessels is not None:\n            self.vessels \u003d (asarray(vessels.resize((w, h), resample\u003dImage.NEAREST)) / 255).astype(int)  # 0-1\n\n            if len(self.vessels.shape) \u003d\u003d 3:\n                self.vessels \u003d self.vessels[:, :, 1]\n            \n        self.mask \u003d asarray(mask.resize((w,h))).astype(int) / 255\n        self.mask \u003d self.mask[:,:,1].astype(int)\n        \n        self.id \u003d id\n\n    def draw_tensor(self):\n        \"\"\"\n        TODO This is very bad dependency to other functionality, this class should be independent, it was created only for tests and it should be removed when will be unused\n        \"\"\"\n        draw_images([self.base_image, self.corrected, self.vessels, self.mask])\n\n    def __repr__(self):\n        return \u0027{}: base_image: {}\u0027.format(self.id, self.base_image.shape)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "LOSR7TPcz7sN",
        "colab_type": "text"
      },
      "source": [
        "### Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "rRcBGhpIz7sO",
        "colab_type": "code",
        "colab": {}
      },
      "source": "def create_tensor_from_file():\n    images_path \u003d sorted(glob.glob(\u0027data/image/*\u0027))\n    for i in range(1, 40+1):\n        logging.info(\u0027Process i: {}\u0027.format(i))\n        base_image \u003d Image.open(IMAGE_PATH.format(i))\n        mask \u003d Image.open(MASK_PATH.format(i))\n        vessels \u003d Image.open(MANUAL_PATH.format(i))\n        yield Tensor(base_image, vessels, mask, i)\n\ndef create_samples_from_tensor(tensor: Tensor):\n    logging.info(\u0027Create samples from tensor: {}\u0027.format(tensor))\n    X, Y \u003d list(), list()\n    for (x, y), value in np.ndenumerate(tensor.mask):\n        if x + PATCH_SIZE \u003c\u003d tensor.corrected.shape[0] and y + PATCH_SIZE \u003c\u003d tensor.corrected.shape[1]:\n            center_x, center_y \u003d x + HALF_OF_PATCH_SIZE, y + HALF_OF_PATCH_SIZE\n            if tensor.mask[center_x][center_y] \u003d\u003d 1:\n                X.append(tensor.corrected[x: x + PATCH_SIZE, y: y + PATCH_SIZE])\n                Y.append(tensor.vessels[center_x][center_y])\n    return X, Y\n\ndef random_undersampling(X, y):\n    \"\"\"\n    In this moment we will lose order of samples\n    \"\"\"\n    minority_value, majority_value \u003d 1, 0\n    new_X, new_y \u003d list(), list()\n    length \u003d len(y)\n    quantity_of_minority \u003d sum(y)\n    quantity_of_majority \u003d length - quantity_of_minority\n    indexes_list \u003d list(range(length))\n    random.shuffle(indexes_list)\n    skipped, to_skip \u003d 0, quantity_of_majority - quantity_of_minority\n    assert to_skip \u003e\u003d 0\n    for index in indexes_list:\n        if skipped \u003c to_skip and y[index] \u003d\u003d majority_value:\n            skipped +\u003d 1\n        else:\n            new_X.append(X[index])\n            new_y.append(y[index])\n\n    result_X, result_Y \u003d sklearn.utils.shuffle(new_X, new_y, random_state\u003d0)\n    return result_X, result_Y\n\n\ndef preprocess_image(tensor: Tensor):\n    edge_sobel \u003d sobel(tensor.corrected)\n    normalized_image \u003d cv2.normalize(edge_sobel, None, alpha\u003d0, beta\u003d255, norm_type\u003dcv2.NORM_MINMAX, dtype\u003dcv2.CV_32F)\n    _, thresholded_image \u003d cv2.threshold(normalized_image, 20, 255, cv2.THRESH_BINARY)\n    normalized_image \u003d cv2.normalize(thresholded_image, None, alpha\u003d0, beta\u003d255, norm_type\u003dcv2.NORM_MINMAX, dtype\u003dcv2.CV_32F)\n    cleaned_image \u003d (normalized_image * tensor.mask).astype(int)\n    return normalized_image",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "JoxlNdN1z7sQ",
        "colab_type": "text"
      },
      "source": [
        "### Collect patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "3RlTOif1z7sR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "ff6d700a-519d-4080-ac4e-bb12652165b3"
      },
      "source": [
        "complete_X, complete_y \u003d None, None\n",
        "for tensor in create_tensor_from_file():\n",
        "    X, y \u003d create_samples_from_tensor(tensor)\n",
        "\n",
        "    logging.info(\u0027Patches were created\u0027)\n",
        "    logging.info(\u0027Original dataset shape {}\u0027.format(Counter(y)))\n",
        "    X, y \u003d random_undersampling(X, y)\n",
        "\n",
        "    logging.debug(\u0027Resampled dataset shape {}\u0027.format(Counter(y)))\n",
        "\n",
        "    start_index \u003d 0\n",
        "    end_index \u003d min(start_index + SPLIT_PATCHES_SIZE, len(X))  # tricky way to avoid OutOfIndexError\n",
        "    logging.info(\u0027Splitting set. Range: {}:{} Progress of this tensor: {}% Time: {}\u0027.format(\n",
        "        start_index, end_index, round(start_index / len(X) * 100), strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())))\n",
        "    X_subset, y_subset \u003d X[start_index:end_index], y[start_index:end_index]\n",
        "    logging.info(\u0027Cut dataset result countered shape {}\u0027.format(Counter(y_subset)))\n",
        "\n",
        "    X_subset \u003d np.array(X_subset).reshape(len(X_subset), PATCH_SIZE, PATCH_SIZE, 1)\n",
        "    y_subset \u003d to_categorical(y_subset)\n",
        "    logging.debug(\u0027Shape X: {}, y: {}\u0027.format(X_subset.shape, y_subset.shape))\n",
        "    \n",
        "    \n",
        "    if complete_X is None:\n",
        "        complete_X \u003d deepcopy(X_subset)\n",
        "        complete_y \u003d deepcopy(y_subset)\n",
        "    else:\n",
        "        complete_X \u003d np.vstack((complete_X, deepcopy(X_subset)))\n",
        "        complete_y \u003d np.vstack((complete_y, deepcopy(y_subset)))\n",
        "\n",
        "logging.info(\u0027Complete datasets shapes: {} {}\u0027.format(complete_X.shape, complete_y.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Process i: 1\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
            "INFO:root:Create samples from tensor: 1: base_image: (2336, 3504, 3)\n",
            "INFO:root:Patches were created\n",
            "INFO:root:Original dataset shape Counter({0: 6396249, 1: 408568})\n",
            "DEBUG:root:Resampled dataset shape Counter({1: 408568, 0: 408568})\n",
            "INFO:root:Splitting set. Range: 0:2500 Progress of this tensor: 0% Time: 2019-05-06 16:08:49\n",
            "INFO:root:Cut dataset result countered shape Counter({1: 1267, 0: 1233})\n",
            "DEBUG:root:Shape X: (2500, 48, 48, 1), y: (2500, 2)\n",
            "INFO:root:Process i: 2\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
            "INFO:root:Create samples from tensor: 2: base_image: (2336, 3504, 3)\n",
            "INFO:root:Patches were created\n",
            "INFO:root:Original dataset shape Counter({0: 6263456, 1: 542745})\n",
            "DEBUG:root:Resampled dataset shape Counter({1: 542745, 0: 542745})\n",
            "INFO:root:Splitting set. Range: 0:2500 Progress of this tensor: 0% Time: 2019-05-06 16:09:29\n",
            "INFO:root:Cut dataset result countered shape Counter({1: 1271, 0: 1229})\n",
            "DEBUG:root:Shape X: (2500, 48, 48, 1), y: (2500, 2)\n",
            "INFO:root:Process i: 3\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
            "INFO:root:Create samples from tensor: 3: base_image: (2336, 3504, 3)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lew-Eh1W4vPn",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDXO0niF4u0k",
        "colab_type": "code",
        "colab": {},
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "tb_call_back \u003d keras.callbacks.TensorBoard(log_dir\u003dLOG_DIR, histogram_freq\u003d0, write_graph\u003dTrue,\n",
        "                                                write_images\u003dTrue)\n",
        "checkpoint \u003d ModelCheckpoint(FILE_PATH, save_weights_only\u003dFalse, monitor\u003d\u0027val_acc\u0027, verbose\u003d0,\n",
        "                                          save_best_only\u003dTrue, mode\u003d\u0027max\u0027)\n",
        "def get_model():\n",
        "    model \u003d Sequential()\n",
        "    model.add(Conv2D(32, kernel_size\u003d(3,3),activation\u003d\u0027relu\u0027,input_shape\u003d(PATCH_SIZE,PATCH_SIZE,1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(32, (3, 3), activation\u003d\u0027relu\u0027))\n",
        "    model.add(MaxPooling2D(pool_size\u003d(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation\u003d\u0027relu\u0027))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, (3, 3), activation\u003d\u0027relu\u0027))\n",
        "    model.add(MaxPooling2D(pool_size\u003d(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation\u003d\u0027relu\u0027))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(128, (3, 3), activation\u003d\u0027relu\u0027))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation\u003d\u0027relu\u0027))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(128, activation\u003d\u0027relu\u0027))\n",
        "    model.add(Dense(2, activation\u003d\u0027softmax\u0027))\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C34beBxy2fDl",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6LKxC8U2kQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "50035ed0-bdf0-4861-c43f-476713d2ddf9",
        "pycharm": {}
      },
      "source": "from sklearn.model_selection import KFold\nkf \u003d KFold(n_splits\u003d4)\nkf.get_n_splits(complete_X)\ncvscores \u003d []\nfor train, test in kf.split(complete_X):\n    model \u003d get_model()\n    model.compile(optimizer\u003d\u0027adam\u0027, loss\u003d\u0027categorical_crossentropy\u0027, metrics\u003d[\u0027accuracy\u0027])\n    model.fit(complete_X[train], complete_y[train], epochs\u003d70, batch_size\u003d32, verbose\u003d0)\n    scores \u003d model.evaluate(complete_X[test], complete_y[test], verbose\u003d0)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\nprint(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 80.00%\n",
            "acc: 20.00%\n",
            "acc: 60.00%\n",
            "acc: 80.00%\n",
            "acc: 40.00%\n",
            "acc: 100.00%\n",
            "acc: 60.00%\n",
            "acc: 40.00%\n",
            "acc: 60.00%\n",
            "acc: 20.00%\n",
            "56.00% (+/- 24.98%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "vq9kFjDYz7sV",
        "colab_type": "code",
        "colab": {},
        "outputId": "0fb88d12-7d09-4662-9b31-e1166abded28"
      },
      "source": [
        "model \u003d get_model()\n",
        "logging.info(\u0027Created keras model\u0027)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/pluto/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/pluto/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/pluto/anaconda3/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate \u003d 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/pluto/anaconda3/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate \u003d 1 - keep_prob`.\n",
            "INFO:root:Created keras model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "RGDgqsX6z7sX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, X):\n",
        "    input \u003d X\n",
        "    if len(input.shape) \u003d\u003d 2:\n",
        "        input \u003d input.reshape(1, PATCH_SIZE, PATCH_SIZE, 1)\n",
        "        logging.debug(\u0027Reshaped before prediction\u0027)\n",
        "    result \u003d model.predict(input)\n",
        "    logging.debug(\u0027Predicted: {}, return {}\u0027.format(result, np.argmax(result)))\n",
        "    logging.debug(\u0027For: {}\u0027.format(input))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {},
        "id": "zZl_Fej3z7sZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X, y, validation_split\u003d0.1, epochs\u003d150, batch_size\u003d32, callbacks\u003d[tb_call_back, checkpoint], verbose\u003d1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "YDHX_UFAz7sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer\u003d\u0027adam\u0027, loss\u003d\u0027categorical_crossentropy\u0027, metrics\u003d[\u0027accuracy\u0027])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "Anc3RF8Mz7sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": "model.load_weights(FILE_PATH)\nmodel.compile(optimizer\u003d\u0027adam\u0027, loss\u003d\u0027categorical_crossentropy\u0027, metrics\u003d[\u0027accuracy\u0027])",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Predict on 3",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "INFO:root:Process i: 41\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
            "INFO:root:Process i: 42\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
            "INFO:root:Process i: 43\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
            "INFO:root:Process i: 44\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
            "INFO:root:Process i: 45\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "from scipy import ndimage\nfor i in range(41, 46):\n    logging.info(\u0027Process i: {}\u0027.format(i))\n    base_image \u003d Image.open(IMAGE_PATH.format(i))\n    mask \u003d Image.open(MASK_PATH.format(i))\n    tensor \u003d Tensor(base_image\u003dbase_image, mask\u003dmask, id\u003di)\n    img\u003dpreprocess_image(tensor)\n    img \u003d ndimage.binary_erosion(img).astype(img.dtype)\n    img \u003d ndimage.binary_dilation(img).astype(img.dtype) * 255\n    plt.imsave(\u0027data/predicted_3/{}.jpg\u0027.format(i),img)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z6Knq5GMTex4",
        "pycharm": {},
        "colab": {}
      },
      "source": "!rm -rf tb_logs* Graph",
      "execution_count": 0,
      "outputs": []
    }
  ]
}