{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {}
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/plutasnyy/recognizeeyebloodvessels/blob/master/recog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USZVSMyr0G-Y",
    "pycharm": {}
   },
   "source": [
    "### Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "WsqIed0l0K10",
    "outputId": "360e67e2-c2a5-4d4e-ff1c-58745af6f797",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/plutasnyy/recognizeeyebloodvessels.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFye3vkR0b9m",
    "pycharm": {}
   },
   "source": [
    "### Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PNwfNmJXz7r-",
    "outputId": "5655ad01-31f3-4098-bdf3-fa918003d489",
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from IPython import get_ipython\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from collections import Counter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from numpy import asarray\n",
    "from skimage import transform, exposure\n",
    "from skimage.filters import sobel\n",
    "\n",
    "import sklearn\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NqkqIZDLz7sC",
    "pycharm": {}
   },
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgf3O4aUz7sD",
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATCH_SIZE = 48\n",
    "HALF_OF_PATCH_SIZE = int(PATCH_SIZE / 2)\n",
    "SPLIT_PATCHES_SIZE = 2500\n",
    "BASE_PATH = 'data'\n",
    "IMAGE_PATH = BASE_PATH + '/image/{}.jpg'\n",
    "MASK_PATH = BASE_PATH + '/mask/{}.tif'\n",
    "MANUAL_PATH = BASE_PATH + '/manual/{}.tif'\n",
    "PREDICTED_3 = BASE_PATH + '/predicted_3/{}.jpg'\n",
    "PREDICTED_NN = BASE_PATH + '/predicted_nn/{}.jpg'\n",
    "FILE_PATH = 'adam_0914_lr1e5.hdf5'\n",
    "LOG_DIR = 'tb_logs'\n",
    "LONG_EDGE_SIZE = None\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKj0luElz7sF",
    "pycharm": {}
   },
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "7O3ySi1WGGMl",
    "outputId": "590bc23d-4e65-4973-c967-72e84c3394a7",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "\n",
    "import os\n",
    "if not os.path.exists(LOG_DIR):\n",
    "  os.makedirs(LOG_DIR)\n",
    "  \n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR))\n",
    "\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "\n",
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rr_kJmuxz7sH",
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8RVoB1pnz7sI",
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def correct_image(image):\n",
    "    #TODO run this function only when process tensor, not during creating an object\n",
    "    logging.info('Correct an image with shape: {}'.format(image.shape))\n",
    "    bw_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    image_adapt = exposure.equalize_adapthist(bw_image)\n",
    "    logarithmic_corrected = exposure.adjust_log(image_adapt, 1)\n",
    "    return logarithmic_corrected\n",
    "  \n",
    "def draw_images(images: list):\n",
    "    logging.info('Draw {} images'.format(len(images)))\n",
    "    size = np.ceil(np.sqrt(len(images)))\n",
    "    fig = plt.figure(figsize=(32, 32))\n",
    "    for i, img in enumerate(images):\n",
    "        fig.add_subplot(size, size, i + 1)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_grey_image(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAv8KAJiz7sK",
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePVowPN-z7sL",
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, base_image, vessels, mask, id):\n",
    "        assert base_image.size == vessels.size, 'Images have different sizes'\n",
    "        assert mask.size == vessels.size, 'Mask has wrong size'\n",
    "\n",
    "        # long_edge = max(base_image.size)\n",
    "        # scale = LONG_EDGE_SIZE / long_edge\n",
    "        scale=1\n",
    "        w, h = base_image.size\n",
    "        c = len(base_image.getbands())\n",
    "        w, h = int(w * scale), int(h * scale)\n",
    "        logging.info(\n",
    "            'Tensor resize from {} to {} with {} scale'.format((base_image.size, c), (w, h, c), round(scale, 2)))\n",
    "\n",
    "        self.base_image = asarray(base_image.resize((w, h), resample=Image.NEAREST))  # 0-255\n",
    "        self.corrected = correct_image(self.base_image)  # 0-1 TODO VERY BAD DEPENDENCY it should be moved out from this class\n",
    "        self.vessels = (asarray(vessels.resize((w, h), resample=Image.NEAREST)) / 255).astype(int)  # 0-1\n",
    "\n",
    "        if len(self.vessels.shape) == 3:\n",
    "            self.vessels = self.vessels[:, :, 1]\n",
    "            \n",
    "        self.mask = asarray(mask).astype(int) / 255\n",
    "        self.mask = self.mask[:,:,1].astype(int)\n",
    "        \n",
    "        self.id = id\n",
    "\n",
    "    def draw_tensor(self):\n",
    "        \"\"\"\n",
    "        TODO This is very bad dependency to other functionality, this class should be independent, it was created only for tests and it should be removed when will be unused\n",
    "        \"\"\"\n",
    "        draw_images([self.base_image, self.corrected, self.vessels, self.mask])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}: base_image: {}'.format(self.id, self.base_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LOSR7TPcz7sN",
    "pycharm": {}
   },
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRcBGhpIz7sO",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def create_tensor_from_file():\n",
    "    images_path = sorted(glob.glob('data/image/*'))\n",
    "    for i in range(1, 40+1):\n",
    "        logging.info('Process i: {}'.format(i))\n",
    "        base_image = Image.open(IMAGE_PATH.format(i))\n",
    "        mask = Image.open(MASK_PATH.format(i))\n",
    "        vessels = Image.open(MANUAL_PATH.format(i))\n",
    "        yield Tensor(base_image, vessels, mask, i)\n",
    "\n",
    "def create_samples_from_tensor(tensor: Tensor):\n",
    "    logging.info('Create samples from tensor: {}'.format(tensor))\n",
    "    X, Y = list(), list()\n",
    "    for (x, y), value in np.ndenumerate(tensor.mask):\n",
    "        if x + PATCH_SIZE <= tensor.corrected.shape[0] and y + PATCH_SIZE <= tensor.corrected.shape[1]:\n",
    "            center_x, center_y = x + HALF_OF_PATCH_SIZE, y + HALF_OF_PATCH_SIZE\n",
    "            if tensor.mask[center_x][center_y] == 1:\n",
    "                X.append(tensor.corrected[x: x + PATCH_SIZE, y: y + PATCH_SIZE])\n",
    "                Y.append(tensor.vessels[center_x][center_y])\n",
    "    return X, Y\n",
    "\n",
    "def random_undersampling(X, y):\n",
    "    \"\"\"\n",
    "    In this moment we will lose order of samples\n",
    "    \"\"\"\n",
    "    minority_value, majority_value = 1, 0\n",
    "    new_X, new_y = list(), list()\n",
    "    length = len(y)\n",
    "    quantity_of_minority = sum(y)\n",
    "    quantity_of_majority = length - quantity_of_minority\n",
    "    indexes_list = list(range(length))\n",
    "    random.shuffle(indexes_list)\n",
    "    skipped, to_skip = 0, quantity_of_majority - quantity_of_minority\n",
    "    assert to_skip >= 0\n",
    "    for index in indexes_list:\n",
    "        if skipped < to_skip and y[index] == majority_value:\n",
    "            skipped += 1\n",
    "        else:\n",
    "            new_X.append(X[index])\n",
    "            new_y.append(y[index])\n",
    "\n",
    "    result_X, result_Y = sklearn.utils.shuffle(new_X, new_y, random_state=0)\n",
    "    return result_X, result_Y\n",
    "\n",
    "\n",
    "def preprocess_image(tensor: Tensor):\n",
    "    logging.info('Started preprocess a tensor: {}'.format(tensor))\n",
    "    edge_sobel = sobel(tensor.corrected)\n",
    "    normalized_image = cv2.normalize(edge_sobel, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    _, thresholded_image = cv2.threshold(normalized_image, 20, 255, cv2.THRESH_BINARY)\n",
    "    cleaned_image = (thresholded_image * tensor.mask).astype(int)\n",
    "    return np.invert(cleaned_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JoxlNdN1z7sQ",
    "pycharm": {}
   },
   "source": [
    "### Collect patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7235
    },
    "colab_type": "code",
    "id": "3RlTOif1z7sR",
    "outputId": "ff6d700a-519d-4080-ac4e-bb12652165b3",
    "pycharm": {
     "is_executing": true,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "complete_X, complete_y = None, None\n",
    "for tensor in create_tensor_from_file():\n",
    "    X, y = create_samples_from_tensor(tensor)\n",
    "\n",
    "    logging.info('Patches were created')\n",
    "    logging.info('Original dataset shape {}'.format(Counter(y)))\n",
    "    X, y = random_undersampling(X, y)\n",
    "\n",
    "    logging.debug('Resampled dataset shape {}'.format(Counter(y)))\n",
    "\n",
    "    start_index = 0\n",
    "    end_index = min(start_index + SPLIT_PATCHES_SIZE, len(X))  # tricky way to avoid OutOfIndexError\n",
    "    logging.info('Splitting set. Range: {}:{} Progress of this tensor: {}% Time: {}'.format(\n",
    "        start_index, end_index, round(start_index / len(X) * 100), strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())))\n",
    "    X_subset, y_subset = X[start_index:end_index], y[start_index:end_index]\n",
    "    logging.info('Cut dataset result countered shape {}'.format(Counter(y_subset)))\n",
    "\n",
    "    X_subset = np.array(X_subset).reshape(len(X_subset), PATCH_SIZE, PATCH_SIZE, 1)\n",
    "    y_subset = to_categorical(y_subset)\n",
    "    logging.debug('Shape X: {}, y: {}'.format(X_subset.shape, y_subset.shape))\n",
    "    \n",
    "    \n",
    "    if complete_X is None:\n",
    "        complete_X = deepcopy(X_subset)\n",
    "        complete_y = deepcopy(y_subset)\n",
    "    else:\n",
    "        complete_X = np.vstack((complete_X, deepcopy(X_subset)))\n",
    "        complete_y = np.vstack((complete_y, deepcopy(y_subset)))\n",
    "\n",
    "logging.info('Complete datasets shapes: {} {}'.format(complete_X.shape, complete_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lew-Eh1W4vPn",
    "pycharm": {}
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDXO0niF4u0k",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tb_call_back = keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=True,\n",
    "                                                write_images=True)\n",
    "checkpoint = ModelCheckpoint(FILE_PATH, save_weights_only=False, monitor='val_acc', verbose=0,\n",
    "                                          save_best_only=True, mode='max')\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3,3),activation='relu',input_shape=(PATCH_SIZE,PATCH_SIZE,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C34beBxy2fDl",
    "pycharm": {}
   },
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7307
    },
    "colab_type": "code",
    "id": "l6LKxC8U2kQp",
    "outputId": "e223d142-fb75-43e8-e561-d17ebb249b39",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=4)\n",
    "kf.get_n_splits(complete_X)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kf.split(complete_X):\n",
    "    model = get_model()\n",
    "    adam = keras.optimizers.Adam(lr=1e-5, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(complete_X[train], complete_y[train], epochs=50, batch_size=32, verbose=1)\n",
    "    scores = model.evaluate(complete_X[test], complete_y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3MkRNq36rSo",
    "pycharm": {}
   },
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "vq9kFjDYz7sV",
    "outputId": "c8007838-3571-41ee-ae1f-600fd0d1abce",
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "logging.info('Created keras model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vL68g5fS6q1B",
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGDgqsX6z7sX",
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    input = X\n",
    "    if len(input.shape) == 2:\n",
    "        input = input.reshape(1, PATCH_SIZE, PATCH_SIZE, 1)\n",
    "#         logging.debug('Reshaped before prediction')\n",
    "    result = model.predict(input)\n",
    "#     logging.debug('Predicted: {}, return {}'.format(result, np.argmax(result)))\n",
    "#     logging.debug('For: {}'.format(input))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDHX_UFAz7sb",
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=1e-5, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Anc3RF8Mz7sd",
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(FILE_PATH)\n",
    "adam = keras.optimizers.Adam(lr=1e-5, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1168
    },
    "colab_type": "code",
    "id": "zZl_Fej3z7sZ",
    "outputId": "b90978db-5a6e-40ee-c52f-e92fc42818f4",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "model.fit(complete_X, complete_y, validation_split=0.1, epochs=80, batch_size=32, callbacks=[tb_call_back, checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MykklPvMm4QA",
    "pycharm": {}
   },
   "source": [
    "### Greedy predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30pzCNubm4dN",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "for i in range(41, 46):\n",
    "    logging.info('Process i: {}'.format(i))\n",
    "    base_image = Image.open(IMAGE_PATH.format(i))\n",
    "    mask = Image.open(MASK_PATH.format(i))\n",
    "    tensor = Tensor(base_image=base_image, mask=mask, id=i)\n",
    "    img=preprocess_image(tensor)\n",
    "    img = ndimage.binary_erosion(img).astype(img.dtype)\n",
    "    img = ndimage.binary_dilation(img).astype(img.dtype) * 255\n",
    "    plt.imsave('data/predicted_3/{}.jpg'.format(i),img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16fWNYO4nS4_",
    "pycharm": {}
   },
   "source": [
    "### Predict from nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131183
    },
    "colab_type": "code",
    "id": "alr0dLUjnTFL",
    "outputId": "ab59aa48-e134-47ac-bb94-19f6256dffb9",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "from skimage.util import view_as_windows\n",
    "\n",
    "for w in range(44,46):\n",
    "    img = Image.open(IMAGE_PATH.format(w))\n",
    "    mask = Image.open(MASK_PATH.format(w))\n",
    "    mask = np.array(ImageOps.expand(mask, border=PATCH_SIZE, fill='black')).astype(int) / 255\n",
    "    mask = mask[:,:,1].astype(int)\n",
    "\n",
    "    img_with_border = correct_image(np.array(ImageOps.expand(img, border=PATCH_SIZE, fill='black')))\n",
    "    patches_list = view_as_windows(img_with_border, (PATCH_SIZE, PATCH_SIZE))\n",
    "    predicted_img = np.zeros_like(img_with_border)\n",
    "    logging.info('Created patches')\n",
    "\n",
    "    for i in range(patches_list.shape[0]):\n",
    "        logging.info('i: {}'.format(i))\n",
    "        for j in range(patches_list.shape[1]):\n",
    "            x = i + HALF_OF_PATCH_SIZE\n",
    "            y = j + HALF_OF_PATCH_SIZE\n",
    "            if mask[x,y] == 1:\n",
    "                predicted_value = np.argmax(predict(model, patches_list[i][j]))\n",
    "                predicted_img[x][y] = predicted_value * 255\n",
    "    img_without_border = ImageOps.crop(Image.fromarray(predicted_img), PATCH_SIZE)\n",
    "    plt.imsave('{}.jpg'.format(w),asarray(img_without_border))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6Knq5GMTex4",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "!rm -rf tb_logs* Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pVg6GCagoNx9",
    "pycharm": {}
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "olYKki4-oQBW",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, average_precision_score\n",
    "    \n",
    "vessels = Image.open(MANUAL_PATH.format(i))\n",
    "vessels = np.array(vessels).astype(int) / 255\n",
    "vessels = vessels.astype(int)\n",
    "\n",
    "for i in range(41,46):    \n",
    "    predicted = (np.array(Image.open(PREDICTED_NN.format(i))).astype(int)[:,:,1] > 150).astype(int)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(vessels.ravel(), predicted.ravel())\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    acc = (tp+tn)/(tn+fp+fn+tp)\n",
    "    prec = tp/(tp+fp)\n",
    "    sen=tp/(tp+fn)\n",
    "    spec=tn/(tn+fp)\n",
    "    avg_prec = average_precision_score(vessels.ravel(), predicted.ravel())\n",
    "    roc_auc = roc_auc_score(vessels.ravel(), predicted.ravel())\n",
    "    \n",
    "    print(\"Image number: {}\".format(i))\n",
    "    print(\"Prediction type: {}\".format(\"NN\"))\n",
    "    print(\"Confusion matrix [[TN,FP],[FN,TP]]:\\n{}\".format(conf_matrix))\n",
    "    print(\"Accuracy: {0:.4f}, Precision: {1:.4f}, Sensitivity: {2:.4f}, Specificity: {3:.4f}, Average precision-recall: {4:.4f}, ROC-AUC: {5:.4f}\"\n",
    "          .format(acc, prec, sen, spec, avg_prec, roc_auc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "recog.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
