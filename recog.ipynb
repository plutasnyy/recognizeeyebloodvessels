{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recog.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USZVSMyr0G-Y",
        "colab_type": "text"
      },
      "source": [
        "### Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsqIed0l0K10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "1c652bdd-3128-4012-e2cf-919e6541f1d3"
      },
      "source": [
        "!git clone https://github.com/plutasnyy/recognizeeyebloodvessels.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'recognizeeyebloodvessels'...\n",
            "remote: Enumerating objects: 1134, done.\u001b[K\n",
            "remote: Total 1134 (delta 0), reused 0 (delta 0), pack-reused 1134\u001b[K\n",
            "Receiving objects: 100% (1134/1134), 190.43 MiB | 13.26 MiB/s, done.\n",
            "Resolving deltas: 100% (780/780), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFye3vkR0b9m",
        "colab_type": "text"
      },
      "source": [
        "### Importy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "PNwfNmJXz7r-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f82b513f-533f-46fb-d868-926348715588"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from IPython import get_ipython\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "from collections import Counter\n",
        "from time import gmtime, strftime\n",
        "\n",
        "from PIL import Image\n",
        "from copy import deepcopy\n",
        "from numpy import asarray\n",
        "from skimage import transform, exposure\n",
        "from skimage.filters import sobel\n",
        "\n",
        "import sklearn\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "NqkqIZDLz7sC",
        "colab_type": "text"
      },
      "source": [
        "### Zmiene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "fgf3O4aUz7sD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATCH_SIZE = 48\n",
        "HALF_OF_PATCH_SIZE = int(PATCH_SIZE / 2)\n",
        "SPLIT_PATCHES_SIZE = 2500\n",
        "BASE_PATH = 'recognizeeyebloodvessels/data'\n",
        "IMAGE_PATH = BASE_PATH + '/image/{}.jpg'\n",
        "MASK_PATH = BASE_PATH + '/mask/{}.tif'\n",
        "MANUAL_PATH = BASE_PATH + '/manual/{}.tif'\n",
        "FILE_PATH = 'new_best2.hdf5'\n",
        "LOG_DIR = 'tb_logs'\n",
        "LONG_EDGE_SIZE = None\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "cKj0luElz7sF",
        "colab_type": "text"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7O3ySi1WGGMl",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# import os\n",
        "# if not os.path.exists(LOG_DIR):\n",
        "#   os.makedirs(LOG_DIR)\n",
        "  \n",
        "# get_ipython().system_raw(\n",
        "#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "#     .format(LOG_DIR))\n",
        "\n",
        "# get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "# !curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        },
        "id": "Rr_kJmuxz7sH",
        "colab_type": "text"
      },
      "source": [
        "### Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "8RVoB1pnz7sI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_image(image):\n",
        "    #TODO run this function only when process tensor, not during creating an object\n",
        "    logging.info('Correct an image with shape: {}'.format(image.shape))\n",
        "    bw_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    image_adapt = exposure.equalize_adapthist(bw_image)\n",
        "    logarithmic_corrected = exposure.adjust_log(image_adapt, 1)\n",
        "    return logarithmic_corrected\n",
        "  \n",
        "def draw_images(images: list):\n",
        "    logging.info('Draw {} images'.format(len(images)))\n",
        "    size = np.ceil(np.sqrt(len(images)))\n",
        "    fig = plt.figure(figsize=(32, 32))\n",
        "    for i, img in enumerate(images):\n",
        "        fig.add_subplot(size, size, i + 1)\n",
        "        plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def draw_grey_image(image):\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        },
        "id": "qAv8KAJiz7sK",
        "colab_type": "text"
      },
      "source": [
        "### Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "ePVowPN-z7sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tensor:\n",
        "    def __init__(self, base_image, vessels, mask, id):\n",
        "        assert base_image.size == vessels.size, 'Images have different sizes'\n",
        "        assert mask.size == vessels.size, 'Mask has wrong size'\n",
        "\n",
        "        # long_edge = max(base_image.size)\n",
        "        # scale = LONG_EDGE_SIZE / long_edge\n",
        "        scale=1\n",
        "        w, h = base_image.size\n",
        "        c = len(base_image.getbands())\n",
        "        w, h = int(w * scale), int(h * scale)\n",
        "        logging.info(\n",
        "            'Tensor resize from {} to {} with {} scale'.format((base_image.size, c), (w, h, c), round(scale, 2)))\n",
        "\n",
        "        self.base_image = asarray(base_image.resize((w, h), resample=Image.NEAREST))  # 0-255\n",
        "        self.corrected = correct_image(self.base_image)  # 0-1 TODO VERY BAD DEPENDENCY it should be moved out from this class\n",
        "        self.vessels = (asarray(vessels.resize((w, h), resample=Image.NEAREST)) / 255).astype(int)  # 0-1\n",
        "\n",
        "        if len(self.vessels.shape) == 3:\n",
        "            self.vessels = self.vessels[:, :, 1]\n",
        "            \n",
        "        self.mask = asarray(mask.resize((w,h))).astype(int) / 255\n",
        "        self.mask = self.mask[:,:,1].astype(int)\n",
        "        \n",
        "        self.id = id\n",
        "\n",
        "    def draw_tensor(self):\n",
        "        \"\"\"\n",
        "        TODO This is very bad dependency to other functionality, this class should be independent, it was created only for tests and it should be removed when will be unused\n",
        "        \"\"\"\n",
        "        draw_images([self.base_image, self.corrected, self.vessels, self.mask])\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}: base_image: {}'.format(self.id, self.base_image.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "LOSR7TPcz7sN",
        "colab_type": "text"
      },
      "source": [
        "### Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "rRcBGhpIz7sO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tensor_from_file():\n",
        "    images_path = sorted(glob.glob('data/image/*'))\n",
        "    for i in range(1, 40+1):\n",
        "        logging.info('Process i: {}'.format(i))\n",
        "        base_image = Image.open(IMAGE_PATH.format(i))\n",
        "        mask = Image.open(MASK_PATH.format(i))\n",
        "        vessels = Image.open(MANUAL_PATH.format(i))\n",
        "        yield Tensor(base_image, vessels, mask, i)\n",
        "\n",
        "def create_samples_from_tensor(tensor: Tensor):\n",
        "    logging.info('Create samples from tensor: {}'.format(tensor))\n",
        "    X, Y = list(), list()\n",
        "    for (x, y), value in np.ndenumerate(tensor.mask):\n",
        "        if x + PATCH_SIZE <= tensor.corrected.shape[0] and y + PATCH_SIZE <= tensor.corrected.shape[1]:\n",
        "            center_x, center_y = x + HALF_OF_PATCH_SIZE, y + HALF_OF_PATCH_SIZE\n",
        "            if tensor.mask[center_x][center_y] == 1:\n",
        "                X.append(tensor.corrected[x: x + PATCH_SIZE, y: y + PATCH_SIZE])\n",
        "                Y.append(tensor.vessels[center_x][center_y])\n",
        "    return X, Y\n",
        "\n",
        "def random_undersampling(X, y):\n",
        "    \"\"\"\n",
        "    In this moment we will lose order of samples\n",
        "    \"\"\"\n",
        "    minority_value, majority_value = 1, 0\n",
        "    new_X, new_y = list(), list()\n",
        "    length = len(y)\n",
        "    quantity_of_minority = sum(y)\n",
        "    quantity_of_majority = length - quantity_of_minority\n",
        "    indexes_list = list(range(length))\n",
        "    random.shuffle(indexes_list)\n",
        "    skipped, to_skip = 0, quantity_of_majority - quantity_of_minority\n",
        "    assert to_skip >= 0\n",
        "    for index in indexes_list:\n",
        "        if skipped < to_skip and y[index] == majority_value:\n",
        "            skipped += 1\n",
        "        else:\n",
        "            new_X.append(X[index])\n",
        "            new_y.append(y[index])\n",
        "\n",
        "    result_X, result_Y = sklearn.utils.shuffle(new_X, new_y, random_state=0)\n",
        "    return result_X, result_Y\n",
        "\n",
        "\n",
        "def preprocess_image(tensor: Tensor):\n",
        "    logging.info('Started preprocess a tensor: {}'.format(tensor))\n",
        "    edge_sobel = sobel(tensor.corrected)\n",
        "    normalized_image = cv2.normalize(edge_sobel, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "    _, thresholded_image = cv2.threshold(normalized_image, 20, 255, cv2.THRESH_BINARY)\n",
        "    cleaned_image = (thresholded_image * tensor.mask).astype(int)\n",
        "    return np.invert(cleaned_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "JoxlNdN1z7sQ",
        "colab_type": "text"
      },
      "source": [
        "### Collect patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "3RlTOif1z7sR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "ff6d700a-519d-4080-ac4e-bb12652165b3"
      },
      "source": [
        "complete_X, complete_y = None, None\n",
        "for tensor in create_tensor_from_file():\n",
        "    X, y = create_samples_from_tensor(tensor)\n",
        "\n",
        "    logging.info('Patches were created')\n",
        "    logging.info('Original dataset shape {}'.format(Counter(y)))\n",
        "    X, y = random_undersampling(X, y)\n",
        "\n",
        "    logging.debug('Resampled dataset shape {}'.format(Counter(y)))\n",
        "\n",
        "    start_index = 0\n",
        "    end_index = min(start_index + SPLIT_PATCHES_SIZE, len(X))  # tricky way to avoid OutOfIndexError\n",
        "    logging.info('Splitting set. Range: {}:{} Progress of this tensor: {}% Time: {}'.format(\n",
        "        start_index, end_index, round(start_index / len(X) * 100), strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())))\n",
        "    X_subset, y_subset = X[start_index:end_index], y[start_index:end_index]\n",
        "    logging.info('Cut dataset result countered shape {}'.format(Counter(y_subset)))\n",
        "\n",
        "    X_subset = np.array(X_subset).reshape(len(X_subset), PATCH_SIZE, PATCH_SIZE, 1)\n",
        "    y_subset = to_categorical(y_subset)\n",
        "    logging.debug('Shape X: {}, y: {}'.format(X_subset.shape, y_subset.shape))\n",
        "    \n",
        "    \n",
        "    if complete_X is None:\n",
        "        complete_X = deepcopy(X_subset)\n",
        "        complete_y = deepcopy(y_subset)\n",
        "    else:\n",
        "        complete_X = np.vstack((complete_X, deepcopy(X_subset)))\n",
        "        complete_y = np.vstack((complete_y, deepcopy(y_subset)))\n",
        "\n",
        "logging.info('Complete datasets shapes: {} {}'.format(complete_X.shape, complete_y.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Process i: 1\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
            "INFO:root:Create samples from tensor: 1: base_image: (2336, 3504, 3)\n",
            "INFO:root:Patches were created\n",
            "INFO:root:Original dataset shape Counter({0: 6396249, 1: 408568})\n",
            "DEBUG:root:Resampled dataset shape Counter({1: 408568, 0: 408568})\n",
            "INFO:root:Splitting set. Range: 0:2500 Progress of this tensor: 0% Time: 2019-05-06 16:08:49\n",
            "INFO:root:Cut dataset result countered shape Counter({1: 1267, 0: 1233})\n",
            "DEBUG:root:Shape X: (2500, 48, 48, 1), y: (2500, 2)\n",
            "INFO:root:Process i: 2\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
            "INFO:root:Create samples from tensor: 2: base_image: (2336, 3504, 3)\n",
            "INFO:root:Patches were created\n",
            "INFO:root:Original dataset shape Counter({0: 6263456, 1: 542745})\n",
            "DEBUG:root:Resampled dataset shape Counter({1: 542745, 0: 542745})\n",
            "INFO:root:Splitting set. Range: 0:2500 Progress of this tensor: 0% Time: 2019-05-06 16:09:29\n",
            "INFO:root:Cut dataset result countered shape Counter({1: 1271, 0: 1229})\n",
            "DEBUG:root:Shape X: (2500, 48, 48, 1), y: (2500, 2)\n",
            "INFO:root:Process i: 3\n",
            "INFO:root:Tensor resize from ((3504, 2336), 3) to (3504, 2336, 3) with 1 scale\n",
            "INFO:root:Correct an image with shape: (2336, 3504, 3)\n",
            "INFO:root:Create samples from tensor: 3: base_image: (2336, 3504, 3)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lew-Eh1W4vPn",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDXO0niF4u0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tb_call_back = keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=True,\n",
        "                                                write_images=True)\n",
        "checkpoint = ModelCheckpoint(FILE_PATH, save_weights_only=False, monitor='val_acc', verbose=0,\n",
        "                                          save_best_only=True, mode='max')\n",
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3,3),activation='relu',input_shape=(PATCH_SIZE,PATCH_SIZE,1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C34beBxy2fDl",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6LKxC8U2kQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "50035ed0-bdf0-4861-c43f-476713d2ddf9"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=10)\n",
        "kf.get_n_splits(complete_X)\n",
        "cvscores = []\n",
        "for train, test in kf.split(complete_X):\n",
        "  # create model\n",
        "    model = get_model()\n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # Fit the model\n",
        "    model.fit(complete_X[train], complete_y[train], epochs=100, batch_size=32, verbose=0)\n",
        "    # evaluate the model\n",
        "    scores = model.evaluate(complete_X[test], complete_y[test], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 80.00%\n",
            "acc: 20.00%\n",
            "acc: 60.00%\n",
            "acc: 80.00%\n",
            "acc: 40.00%\n",
            "acc: 100.00%\n",
            "acc: 60.00%\n",
            "acc: 40.00%\n",
            "acc: 60.00%\n",
            "acc: 20.00%\n",
            "56.00% (+/- 24.98%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "vq9kFjDYz7sV",
        "colab_type": "code",
        "colab": {},
        "outputId": "0fb88d12-7d09-4662-9b31-e1166abded28"
      },
      "source": [
        "model = get_model()\n",
        "logging.info('Created keras model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/pluto/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/pluto/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/pluto/anaconda3/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/pluto/anaconda3/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "INFO:root:Created keras model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "RGDgqsX6z7sX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, X):\n",
        "    input = X\n",
        "    if len(input.shape) == 2:\n",
        "        input = input.reshape(1, PATCH_SIZE, PATCH_SIZE, 1)\n",
        "        logging.debug('Reshaped before prediction')\n",
        "    result = model.predict(input)\n",
        "    logging.debug('Predicted: {}, return {}'.format(result, np.argmax(result)))\n",
        "    logging.debug('For: {}'.format(input))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {},
        "id": "zZl_Fej3z7sZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X, y, validation_split=0.1, epochs=150, batch_size=32, callbacks=[tb_call_back, checkpoint], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "YDHX_UFAz7sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "Anc3RF8Mz7sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(FILE_PATH)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z6Knq5GMTex4",
        "pycharm": {},
        "colab": {}
      },
      "source": [
        "!rm -rf tb_logs* Graph"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}